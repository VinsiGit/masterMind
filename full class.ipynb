{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a748bee6-9725-4f01-a743-9b38fb25db39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a unique recipe that combines apples with fruit:\n",
      "\n",
      "**Autumn Spice Apple Crisp with Caramelized Pecans and Cranberry Compote**\n",
      "\n",
      "Ingredients:\n",
      "\n",
      "For the crisp topping:\n",
      "\n",
      "* 1 cup rolled oats\n",
      "* 1/2 cup brown sugar\n",
      "* 1/2 cup chopped pecans\n",
      "* 1 tablespoon cinnamon\n",
      "* 1/2 teaspoon nutmeg\n",
      "* 1/4 teaspoon salt\n",
      "\n",
      "For the apple filling:\n",
      "\n",
      "* 6-8 medium-sized apples, peeled and sliced (Granny Smith or a mix of sweet and tart varieties)\n",
      "* 1/4 cup granulated sugar\n",
      "* 2 tablespoons all-purpose flour\n",
      "* 1 teaspoon ground cinnamon\n",
      "* 1/4 teaspoon ground nutmeg\n",
      "\n",
      "For the caramelized pecans:\n",
      "\n",
      "* 1/2 cup chopped pecans\n",
      "* 1 tablespoon unsalted butter\n",
      "* 1 tablespoon brown sugar\n",
      "\n",
      "For the cranberry compote:\n",
      "\n",
      "* 1 cup fresh or frozen cranberries\n",
      "* 2 tablespoons granulated sugar\n",
      "* 1 tablespoon orange juice\n",
      "* 1 tablespoon honey\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Preheat your oven to 375°F (190°C).\n",
      "2. In a large bowl, mix together the oat topping ingredients until well combined.\n",
      "3. In a separate bowl, combine the apple filling ingredients and toss until the apples are evenly coated with sugar, flour, cinnamon, nutmeg, and salt.\n",
      "4. Transfer the apple mixture to a 9x9-inch baking dish and set aside.\n",
      "5. In another bowl, mix together the chopped pecans, butter, brown sugar, and cinnamon for the topping.\n",
      "6. Spread the pecan mixture evenly over the apple filling.\n",
      "7. Bake the crisp in the preheated oven for 35-40 minutes or until the topping is golden brown and the apples are tender.\n",
      "8. While the crisp is baking, combine the cranberry compote ingredients in a small saucepan and bring to a simmer over medium heat.\n",
      "9. Cook the compote for about 10-15 minutes or until the cranberries have popped and the liquid has thickened slightly.\n",
      "10. Serve the warm apple crisp topped with caramelized pecans and spooned over the cranberry compote.\n",
      "\n",
      "This recipe combines the sweetness of apples, the crunch of pecans, and the tanginess of cranberries for a delicious and unique dessert that's perfect for autumnal gatherings or special occasions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import ollama\n",
    "import os\n",
    "\n",
    "class FoodImageClassifier:\n",
    "    CONFIDENCE_THRESHOLD = 0.5\n",
    "\n",
    "    def __init__(self, model_name='llama3.2:1b'):\n",
    "        self.model_name = model_name\n",
    "\n",
    "        # Load the general category model and processor\n",
    "        self.category_processor = AutoImageProcessor.from_pretrained(\"Kaludi/food-category-classification-v2.0\")\n",
    "        self.category_model = AutoModelForImageClassification.from_pretrained(\"Kaludi/food-category-classification-v2.0\")\n",
    "\n",
    "        # Load item-specific models\n",
    "        self.fruit_veg_model = AutoModelForImageClassification.from_pretrained(\"jazzmacedo/fruits-and-vegetables-detector-36\")\n",
    "        \n",
    "        # Map category labels to specific item models\n",
    "        self.category_to_model = {\n",
    "            \"Fruit\": self.fruit_veg_model,\n",
    "            \"Vegetable\": self.fruit_veg_model\n",
    "        }\n",
    "\n",
    "        # Define preprocessing transformations\n",
    "        self.preprocess = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def _validate_image(self, image: Image.Image) -> Image.Image:\n",
    "        \"\"\"\n",
    "        Ensure the image is in JPEG format. If not, convert it to JPEG.\n",
    "        \n",
    "        Parameters:\n",
    "        image (PIL.Image.Image): The input image.\n",
    "\n",
    "        Returns:\n",
    "        PIL.Image.Image: A JPEG format image.\n",
    "        \"\"\"\n",
    "        if image.format != 'JPEG':\n",
    "            image = image.convert(\"RGB\")  # Ensure RGB format for JPEG compatibility\n",
    "            image.save(\"temp_image.jpg\", \"JPEG\")\n",
    "            image = Image.open(\"temp_image.jpg\")  # Reopen as JPEG format\n",
    "        return image\n",
    "\n",
    "    def classify_images(self, images: list[Image.Image]) -> list[tuple]:\n",
    "        \"\"\"\n",
    "        Accepts a list of images, preprocesses, and classifies them into categories and specific items.\n",
    "        \n",
    "        Parameters:\n",
    "        images (list[PIL.Image.Image]): List of images.\n",
    "\n",
    "        Returns:\n",
    "        list: List of (category, item) tuples for each image.\n",
    "        \"\"\"\n",
    "        validated_images = [self._validate_image(img) for img in images]\n",
    "        preprocessed_images = [self.preprocess(img).unsqueeze(0) for img in validated_images]\n",
    "        batch = torch.cat(preprocessed_images, dim=0)\n",
    "\n",
    "        results = []\n",
    "        with torch.no_grad():\n",
    "            category_outputs = self.category_model(batch)\n",
    "\n",
    "        for idx, category_logits in enumerate(category_outputs.logits):\n",
    "            category_idx = torch.argmax(category_logits).item()\n",
    "            category_label = self.category_model.config.id2label[category_idx]\n",
    "\n",
    "            item_model = self.category_to_model.get(category_label)\n",
    "            if item_model is None:\n",
    "                results.append((category_label, None))\n",
    "                continue\n",
    "\n",
    "            with torch.no_grad():\n",
    "                item_logits = item_model(batch[idx].unsqueeze(0))\n",
    "                item_probs = torch.softmax(item_logits.logits, dim=1)\n",
    "                item_confidence, item_idx = torch.max(item_probs, dim=1)\n",
    "                item_confidence = item_confidence.item()\n",
    "                item_idx = item_idx.item()\n",
    "                item_label = item_model.config.id2label[item_idx]\n",
    "\n",
    "            if item_confidence >= self.CONFIDENCE_THRESHOLD:\n",
    "                results.append((category_label, item_label))\n",
    "            else:\n",
    "                results.append((category_label, None))\n",
    "\n",
    "        return results\n",
    "\n",
    "    def generate_recipe(self, classified_items: list[tuple]) -> str:\n",
    "        \"\"\"\n",
    "        Creates a recipe based on the classified ingredients.\n",
    "\n",
    "        Parameters:\n",
    "        classified_items (list[tuple]): List of (category, item) tuples.\n",
    "\n",
    "        Returns:\n",
    "        str: Recipe generated by Ollama model.\n",
    "        \"\"\"\n",
    "        ingredients = [item if item else category for category, item in classified_items]\n",
    "        ingredient_list = \", \".join(ingredients)\n",
    "\n",
    "        response = ollama.chat(model=self.model_name, messages=[\n",
    "            {\n",
    "                'role': \"user\",\n",
    "                'content': f\"Create a unique recipe using the following ingredients: {ingredient_list}.\"\n",
    "            },\n",
    "        ])\n",
    "        return response['message']['content']\n",
    "\n",
    "# Example usage:\n",
    "# Load images\n",
    "images = [Image.open(\"imgs/apple.jpg\")]\n",
    "\n",
    "# Initialize classifier and classify images\n",
    "classifier = FoodImageClassifier()\n",
    "classified_items = classifier.classify_images(images)\n",
    "\n",
    "# Generate and print recipe\n",
    "recipe = classifier.generate_recipe(classified_items)\n",
    "print(recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f23472a-5fe9-4bc8-a906-08234dbf2852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
