{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import urllib\n",
    "from PIL import Image\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(nog niet getest)\n",
    "\n",
    "Doc gebruikt:\n",
    "\n",
    "https://huggingface.co/docs/timm/models/mobilenet-v3\n",
    "\n",
    "https://huggingface.co/docs/transformers/en/model_doc/gpt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "moblinenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('mobilenetv3_large_100', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)\n",
    "\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "img = Image.open(filename).convert('RGB')\n",
    "tensor = transform(img).unsqueeze(0) # transform and add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(tensor)\n",
    "probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
    "print(probabilities.shape)\n",
    "# prints: torch.Size([1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get imagenet class mappings\n",
    "url, filename = (\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", \"imagenet_classes.txt\")\n",
    "urllib.request.urlretrieve(url, filename) \n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "\n",
    "# Print top categories per image\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())\n",
    "# prints class names and probabilities like:\n",
    "# [('Samoyed', 0.6425196528434753), ('Pomeranian', 0.04062102362513542), ('keeshond', 0.03186424449086189), ('white wolf', 0.01739676296710968), ('Eskimo dog', 0.011717947199940681)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "prompt = \"GPT2 is a model developed by OpenAI.\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "gen_tokens = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_length=100,\n",
    ")\n",
    "gen_text = tokenizer.batch_decode(gen_tokens)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made by Copilot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained image model (ResNet)\n",
    "image_model = models.resnet50(pretrained=True)\n",
    "image_model.eval()\n",
    "\n",
    "# Preprocess the image\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def get_image_features(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = preprocess(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = image_model(image)\n",
    "    return features\n",
    "\n",
    "# Load pre-trained language model (GPT-2)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "language_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "def generate_text_from_image(image_path):\n",
    "    # Get image features\n",
    "    features = get_image_features(image_path)\n",
    "    \n",
    "    # Get top categories (assuming features are class probabilities)\n",
    "    top5_prob, top5_catid = torch.topk(features, 5)\n",
    "    \n",
    "    # Convert categories to text\n",
    "    categories_text = \" \".join([str(catid.item()) for catid in top5_catid[0]])\n",
    "    \n",
    "    # Generate text using GPT-2\n",
    "    inputs = tokenizer.encode(categories_text, return_tensors='pt')\n",
    "    outputs = language_model.generate(inputs, max_length=50, num_return_sequences=1)\n",
    "    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "image_path = 'imgs/duck.jpg'\n",
    "generated_text = generate_text_from_image(image_path)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
